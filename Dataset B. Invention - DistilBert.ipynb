{
 "cells": [
  {
   "cell_type": "code",
   "id": "c9d5986285ed389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:10:22.318383Z",
     "start_time": "2024-12-18T13:10:22.303193Z"
    }
   },
   "source": [
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch, csv, ast\n",
    "\n",
    "from sklearn.metrics import accuracy_score  # Example metric\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback  # Import EarlyStoppingCallback\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:26:43.568862Z",
     "start_time": "2024-12-18T00:26:43.555597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n"
   ],
   "id": "e9e7f678ef24920e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "11.8\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Dataset",
   "id": "5ae45d42be055b7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:10.077409Z",
     "start_time": "2024-12-18T08:47:09.562030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the TSV file\n",
    "df = pd.read_csv(\n",
    "    \"merged_output_7.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    "    dtype=str,  # Read two first columns as strings labels as int {'patent_id': str, 'text': str, 'label': }\n",
    "    quoting=csv.QUOTE_NONE,\n",
    ")\n",
    "\n",
    "# Convert the 'label' column from strings to lists of integers\n",
    "df['label'] = df['label'].apply(ast.literal_eval)\n",
    "\n",
    "# Print and inspect the resulting DataFrame\n",
    "print(df.head(10))\n",
    "print(df.shape)\n",
    "df.info()\n"
   ],
   "id": "e2f059366155082c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  patent_id                                               text  \\\n",
      "0  10000379  The invention is directed to a process for the...   \n",
      "1  10001403  This invention relates to a system including a...   \n",
      "2  10002404  A graphics processing unit (GPU) includes prog...   \n",
      "3  10002897  Provided is a solid-state imaging device inclu...   \n",
      "4  10003740  The present disclosure involves systems, softw...   \n",
      "5  10004066  To handle different Quality of Service (QoS) r...   \n",
      "6  10004246  Disclosed are hydrated fat compositions compri...   \n",
      "7  10006614  A lighting device includes a primary housing h...   \n",
      "8  10008125  Multi-user portable electronic devices for imp...   \n",
      "9  10008416  A gate structure is formed over a substrate. T...   \n",
      "\n",
      "                      label  \n",
      "0  [0, 0, 1, 0, 0, 0, 0, 0]  \n",
      "1  [0, 0, 0, 0, 0, 0, 1, 0]  \n",
      "2  [0, 0, 0, 0, 0, 0, 1, 0]  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 1]  \n",
      "4  [0, 0, 0, 0, 0, 0, 1, 1]  \n",
      "5  [0, 0, 0, 0, 0, 0, 0, 1]  \n",
      "6  [1, 0, 0, 0, 0, 0, 0, 0]  \n",
      "7  [0, 1, 0, 0, 0, 1, 0, 0]  \n",
      "8  [0, 0, 0, 0, 0, 0, 1, 1]  \n",
      "9  [0, 0, 0, 0, 0, 0, 0, 1]  \n",
      "(8175, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8175 entries, 0 to 8174\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   patent_id  8175 non-null   object\n",
      " 1   text       8175 non-null   object\n",
      " 2   label      8175 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 191.7+ KB\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Subset data",
   "id": "33bc2378eb090e0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:11.785766Z",
     "start_time": "2024-12-18T08:47:11.749254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = df.iloc[:, 1:3]  # Rows 0 to 9, Columns 1 and 2\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.shape)\n",
    "print(type(df['label'].iloc[0])) # Output: <class 'list'>"
   ],
   "id": "c5f6d3f3342a5c5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text                     label\n",
      "0  The invention is directed to a process for the...  [0, 0, 1, 0, 0, 0, 0, 0]\n",
      "1  This invention relates to a system including a...  [0, 0, 0, 0, 0, 0, 1, 0]\n",
      "2  A graphics processing unit (GPU) includes prog...  [0, 0, 0, 0, 0, 0, 1, 0]\n",
      "3  Provided is a solid-state imaging device inclu...  [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "4  The present disclosure involves systems, softw...  [0, 0, 0, 0, 0, 0, 1, 1]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8175 entries, 0 to 8174\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    8175 non-null   object\n",
      " 1   label   8175 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 127.9+ KB\n",
      "None\n",
      "(8175, 2)\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f40d8cf359d1323"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokenize Dataset\n",
    "text — The original abstract text.  \n",
    "label — The binary vector labels.  \n",
    "input_ids — The tokenized IDs for the abstract.  \n",
    "attention_mask — The attention mask for the input sequences.  "
   ],
   "id": "17b3a39681300435"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:18.662192Z",
     "start_time": "2024-12-18T08:47:17.969857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Hugging Face Dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.info"
   ],
   "id": "c05306cb78d9e2d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'text': Value(dtype='string', id=None), 'label': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, post_processed=None, supervised_keys=None, builder_name=None, dataset_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:18.770081Z",
     "start_time": "2024-12-18T08:47:18.754128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(dataset.info.features)  \n",
    "print(\"\\n\")\n",
    "# Print the first few rows of the dataset\n",
    "print(dataset[:1])  # or dataset.head(10) if using pandas\n",
    "print(dataset)"
   ],
   "id": "9fc6db4ce24c7d34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': Value(dtype='string', id=None), 'label': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
      "\n",
      "\n",
      "{'text': ['The invention is directed to a process for the preparation of a syngas comprising hydrogen and carbon monoxide from a methane comprising gas, which process comprises the steps of: (a) reacting the methane comprising gas with an oxidizing gas in an autothermal reformer to obtain a hot raw syngas comprising carbon monoxide and hydrogen; (b) cooling the hot raw syngas resulting from step (a) to obtain the syngas, wherein step (b) comprises cooling the hot raw syngas by indirect heat exchange against the methane comprising gas used in step (a) and wherein sulphur is added upstream of cooling step (b). The invention also relates to a process for the preparation of hydrocarbon products in which a feed syngas is prepared in the process as described above followed by a desulphurization treatment and the desulphurized syngas is subsequently converted into hydrocarbon products in a Fischer-Tropsch process.'], 'label': [[0, 0, 1, 0, 0, 0, 0, 0]]}\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 8175\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:19.597045Z",
     "start_time": "2024-12-18T08:47:19.580158Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset)",
   "id": "f1466956dd9ed7fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 8175\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:21.143524Z",
     "start_time": "2024-12-18T08:47:21.129533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine length of the longest abstract\n",
    "longest_abstract_length = df['text'].apply(len).max()\n",
    "\n",
    "print(f\"The longest abstract has {longest_abstract_length} characters.\")\n"
   ],
   "id": "aa427c88ca85d5d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest abstract has 4678 characters.\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:49.289170Z",
     "start_time": "2024-12-18T08:47:22.057467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize abstracts and include labels\n",
    "def tokenize_fn(example):\n",
    "    tokens = tokenizer(example['text'], truncation=True, padding='max_length', max_length=512)   # I work in pycharm, where the map progression bar visually is bugged - therefore I ignore that it says 0%. I can verify that the function tokenized_fn work by printing the tokenized_dataset\n",
    "    tokens[\"label\"] = example['label']  # Add labels\n",
    "    return tokens\n",
    "\n",
    "# Tokenize the dataset and keep labels in the same dataset\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=False)\n",
    "print(tokenized_dataset)\n",
    "print(tokenized_dataset.column_names)\n"
   ],
   "id": "cc4328548212f175",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8175 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a2e1e79208e4454b823ad95c77109c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 8175\n",
      "})\n",
      "['text', 'label', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:49.320802Z",
     "start_time": "2024-12-18T08:47:49.300831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Print first row of the tokenized data\n",
    "print(tokenized_dataset[0])\n"
   ],
   "id": "c8b460126f83a281",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The invention is directed to a process for the preparation of a syngas comprising hydrogen and carbon monoxide from a methane comprising gas, which process comprises the steps of: (a) reacting the methane comprising gas with an oxidizing gas in an autothermal reformer to obtain a hot raw syngas comprising carbon monoxide and hydrogen; (b) cooling the hot raw syngas resulting from step (a) to obtain the syngas, wherein step (b) comprises cooling the hot raw syngas by indirect heat exchange against the methane comprising gas used in step (a) and wherein sulphur is added upstream of cooling step (b). The invention also relates to a process for the preparation of hydrocarbon products in which a feed syngas is prepared in the process as described above followed by a desulphurization treatment and the desulphurized syngas is subsequently converted into hydrocarbon products in a Fischer-Tropsch process.', 'label': [0, 0, 1, 0, 0, 0, 0, 0], 'input_ids': [101, 1996, 11028, 2003, 2856, 2000, 1037, 2832, 2005, 1996, 7547, 1997, 1037, 19962, 12617, 9605, 9732, 1998, 6351, 18847, 19491, 2013, 1037, 24481, 9605, 3806, 1010, 2029, 2832, 8681, 1996, 4084, 1997, 1024, 1006, 1037, 1007, 24868, 1996, 24481, 9605, 3806, 2007, 2019, 23060, 28173, 6774, 3806, 1999, 2019, 8285, 23367, 24767, 2000, 6855, 1037, 2980, 6315, 19962, 12617, 9605, 6351, 18847, 19491, 1998, 9732, 1025, 1006, 1038, 1007, 11520, 1996, 2980, 6315, 19962, 12617, 4525, 2013, 3357, 1006, 1037, 1007, 2000, 6855, 1996, 19962, 12617, 1010, 16726, 3357, 1006, 1038, 1007, 8681, 11520, 1996, 2980, 6315, 19962, 12617, 2011, 14958, 3684, 3863, 2114, 1996, 24481, 9605, 3806, 2109, 1999, 3357, 1006, 1037, 1007, 1998, 16726, 21396, 8458, 3126, 2003, 2794, 13909, 1997, 11520, 3357, 1006, 1038, 1007, 1012, 1996, 11028, 2036, 14623, 2000, 1037, 2832, 2005, 1996, 7547, 1997, 18479, 26190, 3688, 1999, 2029, 1037, 5438, 19962, 12617, 2003, 4810, 1999, 1996, 2832, 2004, 2649, 2682, 2628, 2011, 1037, 4078, 5313, 8458, 9496, 9276, 3949, 1998, 1996, 4078, 5313, 8458, 28405, 19962, 12617, 2003, 3525, 4991, 2046, 18479, 26190, 3688, 1999, 1037, 13042, 1011, 19817, 11923, 2818, 2832, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:49.366654Z",
     "start_time": "2024-12-18T08:47:49.352692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print(tokenized_dataset['label'][:5])  # Print the first 5 labels\n",
    "#print(tokenized_dataset['input_ids'][:5])  # Print the first 5 tokenized texts (input_ids)\n"
   ],
   "id": "63590891e791a051",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split tokenized data into train, val and test data",
   "id": "bb198c77fbc1c211"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:49.443449Z",
     "start_time": "2024-12-18T08:47:49.399568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, split the dataset into training and testing (80% train, 20% test)\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "print(train_test_split[\"train\"].shape)\n",
    "print(train_test_split[\"test\"].shape)\n",
    "\n",
    "# Further split the training set into training and validation (80% train, 20% validation)\n",
    "train_val_split = train_test_split['train'].train_test_split(test_size=0.2)\n",
    "print(train_val_split[\"train\"].shape)\n",
    "print(train_val_split[\"test\"].shape)\n",
    "\n",
    "# Combining everything into a DatasetDict for easier handling\n",
    "split_datasets = DatasetDict({\n",
    "    'train': train_val_split['train'],\n",
    "    'validation': train_val_split['test'],\n",
    "    'test': train_test_split['test']\n",
    "})"
   ],
   "id": "ed9a95ef31a2d9e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6540, 4)\n",
      "(1635, 4)\n",
      "(5232, 4)\n",
      "(1308, 4)\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Model and Training Arguments\n",
    "multi-label classification"
   ],
   "id": "8a73e6bee996a388"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:50.061013Z",
     "start_time": "2024-12-18T08:47:49.475365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the model for multi-label classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    num_labels=8,  # Number of classes\n",
    "    problem_type=\"multi_label_classification\"  # Specify multi-label classification\n",
    ")\n",
    "\n",
    "print(model)\n"
   ],
   "id": "6167fdb8474e8d6c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:47:50.122836Z",
     "start_time": "2024-12-18T08:47:50.097879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Freeze all layers except the classification head\n",
    "for param in model.distilbert.parameters():\n",
    "    param.requires_grad = False\n",
    "# Only the classifier layers will be trainable\n",
    "for param in model.pre_classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(model)"
   ],
   "id": "cef29fcba9e99d95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:30:47.934671800Z",
     "start_time": "2024-12-17T22:08:20.547714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print DistilBert model architecture \n",
    "print(model)"
   ],
   "id": "fe6cbec5a08f4737",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Global step: 3 (3 training steps since the dataset is small and batch size is 2).  \n",
    "Training loss: 0.6537 (lower is better; indicates the model is learning).  \n",
    "Samples per second: 2.71 (training speed, works well for small data).  \n",
    "Steps per second: 1.355 (batch processing rate).  \n",
    "Epoch: 3 (completed all 3 epochs).  "
   ],
   "id": "26281cd15f985a84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T11:19:24.226045Z",
     "start_time": "2024-12-18T11:19:24.197359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ChatGPT\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    preds = preds.argmax(axis=1)\n",
    "    # Use sklearn's accuracy_score or other metrics as needed\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return {'accuracy': accuracy_score(labels, preds)}"
   ],
   "id": "e276d3f4de1066cd",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T09:59:08.957432Z",
     "start_time": "2024-12-18T08:49:11.809117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ChatGPT\n",
    "\n",
    "# Training settingswith 5 epochs\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=2,  # Match dataset size\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"steps\",  # Evaluate after a certain number of steps\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,  # Adjust logging steps if necessary\n",
    "    save_steps=1000,  # Set save_steps to be a multiple of eval_steps\n",
    "    eval_steps=1000,  # Evaluate every 1000 steps\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    "    metric_for_best_model=\"accuracy\",  # Monitor the accuracy metric\n",
    "    greater_is_better=True,  # Higher accuracy is better\n",
    ")\n",
    "\n",
    "# Setup EarlyStoppingCallback\n",
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)\n",
    "\n",
    "# Trainer setup with evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_datasets['train'],\n",
    "    eval_dataset=split_datasets['validation'],\n",
    "    compute_metrics=compute_metrics,  # Optional metric computation\n",
    "    callbacks=[early_stopping_callback]  # Add early stopping callback\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n"
   ],
   "id": "eaa9559d5f530214",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13080' max='13080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13080/13080 1:09:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.330300</td>\n",
       "      <td>0.316379</td>\n",
       "      <td>0.069572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>0.282315</td>\n",
       "      <td>0.158257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.271083</td>\n",
       "      <td>0.211774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.274800</td>\n",
       "      <td>0.262882</td>\n",
       "      <td>0.244648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.253300</td>\n",
       "      <td>0.262433</td>\n",
       "      <td>0.285168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.254996</td>\n",
       "      <td>0.308104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.252236</td>\n",
       "      <td>0.305046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.254157</td>\n",
       "      <td>0.335627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.252678</td>\n",
       "      <td>0.336391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.250173</td>\n",
       "      <td>0.331804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.250131</td>\n",
       "      <td>0.337156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.248883</td>\n",
       "      <td>0.349388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.248710</td>\n",
       "      <td>0.337920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13080, training_loss=0.2617912671617047, metrics={'train_runtime': 4195.7689, 'train_samples_per_second': 6.235, 'train_steps_per_second': 3.117, 'total_flos': 3465717946122240.0, 'train_loss': 0.2617912671617047, 'epoch': 5.0})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T10:02:22.373657Z",
     "start_time": "2024-12-18T10:00:18.871901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = trainer.evaluate(split_datasets['validation'])\n",
    "print(results)\n"
   ],
   "id": "5c2321e55b67643b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24888338148593903, 'eval_accuracy': 0.34938837920489296, 'eval_runtime': 123.4734, 'eval_samples_per_second': 10.593, 'eval_steps_per_second': 5.297, 'epoch': 5.0}\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the Model",
   "id": "b006b05f534db684"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "trainer.evaluate(): calculates metrics (e.g., loss) on the validation dataset or any dataset provided. It does not return the predicted labels; it only provides evaluation metrics (like loss) based on the true labels and the model's output. Typically used for monitoring the model during training.\n",
    "\n",
    "trainer.predict(): returns the predicted labels (along with other information like logits) for a given dataset (e.g., test data). Allows for specific metrics like accuracy, precision, recall, etc., on the predictions. Typically used after training is complete to evaluate how well the model performs on unseen data."
   ],
   "id": "bb3a8ce50d54ecda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T10:04:54.631106Z",
     "start_time": "2024-12-18T10:02:22.408574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get predictions on the test set\n",
    "predictions = trainer.predict(split_datasets['test'])\n",
    "\n",
    "# Extract predicted labels and true labels\n",
    "predicted_labels = (predictions.predictions > 0.5).astype(int)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ],
   "id": "3699b54a61f6d379",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.35718654434250763\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the model",
   "id": "aef99243ade2d8ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T10:04:55.305639Z",
     "start_time": "2024-12-18T10:04:54.665984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ChatGPT\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./trained_model\")\n",
    "tokenizer.save_pretrained(\"./trained_model\")\n"
   ],
   "id": "6a55b3a40f6bf624",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./trained_model\\\\tokenizer_config.json',\n",
       " './trained_model\\\\special_tokens_map.json',\n",
       " './trained_model\\\\vocab.txt',\n",
       " './trained_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load former model",
   "id": "cb98d7a6a1a541ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:22:26.556252Z",
     "start_time": "2024-12-18T08:22:26.069148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ChatGPT\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./trained_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./trained_model\")\n"
   ],
   "id": "667469f801efd600",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predictions",
   "id": "246c3dbdbac60afb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T08:45:27.411093Z",
     "start_time": "2024-12-18T08:45:26.352442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ChatGPT\n",
    "# Example input text for prediction\n",
    "input_text = \"A multilayered tube for transporting fuel including an innermost layer (A), an outermost layer (B) and an intermediate layer (C)...\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    predictions = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "# Convert logits to binary predictions (if it's multi-label classification)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "print(predicted_labels)\n"
   ],
   "id": "9f2bbeba7c509d07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "execution_count": 84
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
